# Master Thesis Bioinformatics Workflows

## Install

1. Clone this project.  

    `git clone https://...` 

1. Setup SSH-Keypair. `

    `ssh-keygen -t rsa`

1.  Upload public SSH key to `head.hpc.zhaw.ch`.

    `ssh-copy-id demo@198.51.100.0`

1. Create an alias for task script in your `.bashrc/.zshrc` (simply paste the alias command in the file at the bottom).

    `alias task='./task'`

1. Setup and env file and define the REMOTEPATH, which points to the directorie in which you want to setup the following working area

    `REMOTE_PATH= <Path_to_User>` (example: REMOTE_PATH=/cfs/earth/scratch/$User/work_area/scripts/) 

1. Check the if the task-commands are setup by running

    `task help`

1. Create the directories at the remote path

    `task init`

## Overview of the user setup
The task-commands simplify the interaction with a high performance computing envrironment run on the Slurm Workload Manager. This setup is designed and tested to run on the hardware and software envrionment at ZHAW, altought the general concept and scripts should be transferable to other systems. The following picture depicts an overview of the user interaction.
![HPC_Server_Interaction](https://github.com/SebastianVonRotz/MasterThesis_Bioinformatics/blob/master/assets/HPC_Server_Interaction.JPG)

## Overview of processing scripts on the HPC
Scripts process and transform data in a sequential order. This sequenced processing of the data is depicted in the following picture. Depending on the script certain processing steps need to be fullfilled in order to get the correct inpurt for the current script.

![Scripts_Processing_Overview](https://github.com/SebastianVonRotz/MasterThesis_Bioinformatics/blob/master/assets/Scripts_Processing_Overview.JPG)

## Explanation of the env file content

The env files contains all adjustable variables and paths. Depending on what kind of workflow or script the user wants to execute, certain paths and variables need to be set. This section explains each variable in detail. Furthermore the env-template file is an example of such a file.

1. Explanation of the variables

* The REMOTE_PATH is set by the user individually and points to the directory on the HPC in which the user wants to create and run this project.

`REMOTE_PATH=<Path>`

* The DATASET_NAME defines the name of the dataset and acts as the main tracker of results generated with scripts (Every result directory generated by a script or workflow is with a directory named after the DATASET_NAME variable). Only use letters and "_".

`DATASET_NAME=<Name of Dataset>`

RUN_NAME_IN and RUN_NAME_OUT are secondary tracker of results. The input and output is tracked accoring to this variables. The input and output directories in addition to the script or workflow are named after RUN_NAME_OUT. With the RUN_NAME_OUT variable the input to the script is defined.

`RUN_NAME_IN=<Name>`

`RUN_NAME_OUT=<Name>`

DATA_PATH_IN points to the raw data input of the current dataset. It is used only in the first processing scripts. Path has to end with "/"

`DATA_PATH_IN=<Path>`

Sepcific scripts need the type of flowcell and kit with which the dataset has been generated.

`FLOWCELL=<Flowcell type>`
`KIT=<Kit type>`

FILES_PER_SUBDIR defines the amount of files which are placed in each subdir in the script "basecalling_guppy_array.sh"

`FILES_PER_SUBDIR=<Number of files>`

For the local installation of the guppy basecaller a path needs to point to the "guppy_basecaller" command in order to use it.

`GUPPY_BASECALLER_PATH=<Path to Installation>`

For the local installation of the guppy demultiplexer a path needs to point to the "guppy_barcoder" command in order to use it.

`GUPPY_DEMULTIPLEXING_PATH=<Path to Installation>`

For the local installation of the qcat demultiplexer a path needs to point to the "qcat" command in order to use it.

`QCAT_DEMULTIPLEXING_PATH=<Path to Installation>`

The nanofilt filtering scripts need a quality score and a min, max length variable input

`NANOFILT_QSCORE=<q score>`
`NANOFILT_MIN_LENGTH=<min length>`
`NANOFILT_MAX_LENGTH=<max length>`

For the local installation of the kraken2 classifier a path needs to point to the "kraken2" command in order to use it. Furthermore a reference database needs to be specified.

`PATH_KRAKEN2=<Path to Installation>`
`PATH_KRAKEN2_DB=<Path to Database>`

For the local installation of the qcat demultiplexer a path needs to point to the "qcat" command in order to use it.

`PATH_KRONATOOLS=<Path to Installation>`

## Creating an env file
1. Create an env file and edit it

`nano env`

2. Add the following to the env file:
```
REMOTE_PATH=/cfs/earth/scratch/voro/scripts
DATASET_NAME=Dataset_5
DATA_PATH_IN=../data/Dataset_5/
RUN_NAME_IN=Step_01
RUN_NAME_OUT=Step_01
FLOWCELL=FLO-FLG001
KIT=SQK-16S024
FILES_PER_SUBDIR=20
GUPPY_BASECALLER_PATH=../local_apps/ont-guppy-cpu/bin/guppy_basecaller
GUPPY_DEMULTIPLEXING_PATH=../local_apps/ont-guppy-cpu/bin//guppy_barcoder
QCAT_DEMULTIPLEXING_PATH=../python/bin/qcat
NANOFILT_QSCORE=7
NANOFILT_MIN_LENGTH=1000
NANOFILT_MAX_LENGTH=2000
PATH_KRAKEN2=../local_apps/kraken2/Kraken_Installation/kraken2 
PATH_KRAKEN2_DB=../local_apps/kraken2/scripts/GREENGENES/
PATH_KRONATOOLS=../local_apps/krona/KronaTools-2.7.1/bin/bin/ktImportTaxonomy
```

3. **or** rename and adapt the "env-template" (rename to "env")

## Step by Step Processing of Scripts
This section describes the step by step processing of data

1. Prerequisite: Section "Install" is successfuly executed

1. Prerequisite: Section "Creating an env file" is successfuly executed

1. Transfer data into the directory path with the following command (This has to be executed on the HPC). It is important the the corresponding raw data .fast5 files are with the directory named accodirng to the DATASET_NAME (no subddirectories allowed).

`cp -avr <Path to dir with Data> <$USER/WorkArea/data>`

1. Check that necessary variables are set to run a specific script, then use the following command.

`run script <Name of the scrip>`

## Workflow Processing of Scripts

## Available scripts and programs
![Scripts_Detailed.JPG](https://github.com/SebastianVonRotz/MasterThesis_Bioinformatics/blob/master/assets/Scripts_Detailed.JPG)






##### Helpers

Convert dos file to unix file.  

`dos2unix <filename>`


