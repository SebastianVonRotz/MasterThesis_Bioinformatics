#!/bin/bash

function init() {
    load-env
    ssh -t head.hpc.zhaw.ch "mkdir -p $REMOTE_PATH/work_area/{data,scripts,data_temp,results}"
    echo "The directories are created in the following dir: $REMOTE_PATH/work_area, with following subddirs:"
    ssh -t head.hpc.zhaw.ch "ls -l $REMOTE_PATH/work_area/"
}

function list-scripts() {
    ls -l ./scripts
}

function run-script() {
    load-env
    scp ./scripts/$1 head.hpc.zhaw.ch:$REMOTE_PATH
    scp env head.hpc.zhaw.ch:$REMOTE_PATH
    echo "Script: $1 and env file are uploaded "

    if [ $1 == "r_kraken2_report.sh" ]; then
        echo "Additional upload of scripts are needed for r_kraken2_report.sh"
        scp ./scripts/kraken2_report_stats.R head.hpc.zhaw.ch:$REMOTE_PATH
    else
        echo "No additional uploads"
    fi
    
    ssh head.hpc.zhaw.ch "cd $REMOTE_PATH; pwd; sbatch $1"
    echo "Script: $1 is running"
}

function run-ws() {
    export $(cat .env)
    echo "Uploading scripts with the workflow name $1 "
    scp ./scripts/$1* head.hpc.zhaw.ch:$REMOTE_PATH
    scp .env head.hpc.zhaw.ch:$REMOTE_PATH
}

function conn-hpc() {
    echo "starting ssh connection to the hpc"
    ssh -t head.hpc.zhaw.ch "cd /cfs/earth/scratch/voro/scripts; bash"
}

function load-env() {
    export $(cat env)
    echo "The env file: $1 is loaded"
}

function hpc-status() {
    load-env $2
    echo "Get queue status"
    ssh head.hpc.zhaw.ch "cd $REMOTE_PATH; pwd; squeue"
}

function job-status() {
    echo "Get job #$1 status"
    ssh head.hpc.zhaw.ch "cd $REMOTE_PATH; pwd; sacct -j $1 --format=JobName,CPUTimeRAW,Submit,Start,End,Elapsed"
}

function node-status() {
    echo "Get node status"
    ssh head.hpc.zhaw.ch "cd $REMOTE_PATH; pwd; sinfo"
}

function cancel-job() {
    echo "Cancel the job #$1"
    ssh head.hpc.zhaw.ch "cd $REMOTE_PATH; pwd; scancel $1"
}

function dl-data() {
    echo "Downloading data from: $1"
    scp -r head.hpc.zhaw.ch:$1 ./data_temp
}

function help() {
echo
echo
echo "task commmands:"
echo
echo "(task) command <argument>     description"
echo "---------------------------------------------------------------------------------------------"
echo "init                          Creates project directories at the specified REMOTE_PATH"
echo "list-scripts                  Returns a List of available scripts and workflows"
echo "run-script <Script Name>      Execute a script based on name argument"
echo "run-ws <Workflow Name>        Exceute a workflow base on the name argument"
echo "conn-hpc                      Connect to the head node on the HPC"
echo "load-env                      Export the variables of the env file"
echo "hpc-status                    Get an overview the current jobs running on the HPC"
echo "job-status <Job ID>           Get overview stats on a job based on its id argument"
echo "node-status                   Get an overview of the status of the available nodes on the HPC"
echo "cancel-job <Job ID>           Cancel a job based on its id argument"
echo "dl-data <Path_to_data>        Dowload data based on a path into the local temp_data directory"
echo 
echo "Helping commands:"
echo
echo "command                       description"
echo "--------------------------------------------"
echo "dos2unix                       Convert dos files into unix files. Apply if a problem comes up"
echo
}

# Switch case for script parameter 1
case "$1" in
    start)
        start
        ;;
    init)
        init
        ;;
    list-scripts)
        list-scripts
        ;;
    run-script)
        run-script $2
        ;;
    run-ws)
        run-workflow $2
        ;;
    conn-hpc)
        conn-hpc
        ;;
    load-env)
        load-env $2
        ;;
    hpc-status)
        hpc-status
        ;;
    job-status)
        job-status $2
        ;;
    node-status)
        node-status
        ;;
    cancel-job)
        cancel-job $2
        ;;
    dl-data)
        dl-data $2
        ;;
    *)
        help help
        exit 1
esac